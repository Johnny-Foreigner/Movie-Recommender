{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System\n",
    "\n",
    "You will be making movie recommendations based on the <a href=\"https://grouplens.org/datasets/movielens/latest/\">MovieLens dataset</a> from the GroupLens research lab at the University of Minnesota. Unless you are planning to run your analysis on a paid cloud platform, we recommend that you use the \"small\" dataset containing 100,000 user ratings (and potentially, only a particular subset of that dataset).\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "    Build a model that provides top 5 movie recommendations to a user, based on their ratings of other movies.\n",
    "\n",
    "The MovieLens dataset is a \"classic\" recommendation system dataset, that is used in numerous academic papers and machine learning proofs-of-concept. You will need to create the specific details about how the user will provide their ratings of other movies, in addition to formulating a more specific business problem within the general context of \"recommending movies\".\n",
    "\n",
    "#### Collaborative Filtering\n",
    "At minimum, your recommendation system must use collaborative filtering. If you have time, consider implementing a hybrid approach, e.g. using collaborative filtering as the primary mechanism, but using content-based filtering to address the <a href=\"https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)\">cold start</a> problem.\n",
    "\n",
    "#### Evaluation\n",
    "The MovieLens dataset has explicit ratings, so achieving some sort of evaluation of your model is simple enough. But you should give some thought to the question of metrics. Since the rankings are ordinal, we know we can treat this like a regression problem. But when it comes to regression metrics there are several choices: RMSE, MAE, etc. Here are some further ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import pyspark.sql.functions\n",
    "from pyspark.sql.functions import col, min, max, avg\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Start a spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the data\n",
    "\n",
    "# ! wget -P ../../data http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "\n",
    "# with zipfile.ZipFile('../../data/ml-latest-small.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('../../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration & manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data with spark DataFrames\n",
    "links = spark.read.csv('../../data/ml-latest-small/links.csv', header=True)\n",
    "movies = spark.read.csv(\"../../data/ml-latest-small/movies.csv\", header=True)\n",
    "ratings = spark.read.csv(\"../../data/ml-latest-small/ratings.csv\", header=True)\n",
    "tags = spark.read.csv(\"../../data/ml-latest-small/tags.csv\", header=True)\n",
    "\n",
    "tags = tags.select('userId', 'movieId', 'tag')\n",
    "\n",
    "# Join tabels\n",
    "df = ratings.join(tags, [\"userId\", \"movieId\"], \"left\")\n",
    "df = df.join(movies, [\"movieId\"], \"left\")\n",
    "\n",
    "#Convert to Pandas Dataframe and filter columns\n",
    "pandas_df=df.toPandas()\n",
    "pandas_df = pandas_df[['userId', 'rating', 'movieId', 'title', 'genres', 'tag', 'timestamp']]\n",
    "\n",
    "# Fill null tags with \"Unkown\"\n",
    "pandas_df.tag = pandas_df.tag.fillna(\"Uknown\")\n",
    "\n",
    "# LabelEncode tags and genres\n",
    "le = LabelEncoder()\n",
    "le_genres = LabelEncoder()\n",
    "tags_le = le.fit_transform(pandas_df.tag)\n",
    "genres_le = le_genres.fit_transform(pandas_df.genres)\n",
    "\n",
    "pandas_df = pandas_df.drop(['genres', 'tag'], axis=1)\n",
    "pandas_df['tags_le'] = pd.Series(tags_le, index=pandas_df.index).astype(str)\n",
    "pandas_df['genres_le'] = pd.Series(genres_le, index=pandas_df.index).astype(str)\n",
    "\n",
    "# Convert back Spark Dataframe\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# Change dtypes from strings to numeric\n",
    "df = df.select(df.userId.cast(\"integer\"),\n",
    "               df.movieId.cast(\"integer\"),\n",
    "               df.rating.cast(\"double\"),\n",
    "               df.genres_le.cast(\"integer\"),\n",
    "               df.tags_le.cast(\"integer\"),\n",
    "               df.timestamp.cast(\"integer\"),\n",
    "               df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- genres_le: integer (nullable = true)\n",
      " |-- tags_le: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+-------+---------+--------------------+\n",
      "|userId|movieId|rating|genres_le|tags_le|timestamp|               title|\n",
      "+------+-------+------+---------+-------+---------+--------------------+\n",
      "|     1|      1|   4.0|      351|    520|964982703|    Toy Story (1995)|\n",
      "|     1|      3|   4.0|      732|    520|964981247|Grumpier Old Men ...|\n",
      "|     1|      6|   4.0|      260|    520|964982224|         Heat (1995)|\n",
      "|     1|     47|   5.0|      937|    520|964983815|Seven (a.k.a. Se7...|\n",
      "|     1|     50|   5.0|      790|    520|964982931|Usual Suspects, T...|\n",
      "|     1|     70|   3.0|      214|    520|964982400|From Dusk Till Da...|\n",
      "|     1|    101|   5.0|      430|    520|964980868|Bottle Rocket (1996)|\n",
      "|     1|    110|   4.0|      290|    520|964982176|   Braveheart (1995)|\n",
      "|     1|    151|   5.0|      281|    520|964984041|      Rob Roy (1995)|\n",
      "|     1|    157|   5.0|      741|    520|964984100|Canadian Bacon (1...|\n",
      "+------+-------+------+---------+-------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.27% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = df.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = df.select(\"userId\").distinct().count()\n",
    "num_movies = df.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per movie: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|10.559132044426162|\n",
      "+------------------+\n",
      "\n",
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|168.32295081967214|\n",
      "+------------------+\n",
      "\n",
      "Num of users: 610\n",
      "Num of movies: 9724\n",
      "Num of tags: 1544\n",
      "Num of rows in ratings: 100836\n",
      "Num of rows in tags: 3683\n",
      "Num of rows in combined dataframe: 102677\n"
     ]
    }
   ],
   "source": [
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "df.groupBy(\"movieID\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "df.groupBy(\"movieID\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "df.groupBy(\"userID\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "df.groupBy(\"userID\").count().select(avg(\"count\")).show()\n",
    "\n",
    "print(\"Num of users: \" + str(df.groupBy(\"userID\").count().count()))\n",
    "print(\"Num of movies: \" + str(df.groupBy(\"movieID\").count().count()))\n",
    "print(\"Num of tags: \" + str(df.groupBy(\"tags_le\").count().count()))\n",
    "\n",
    "print(\"Num of rows in ratings: \" + str(ratings.count()))\n",
    "\n",
    "print(\"Num of rows in tags: \" + str(tags.count()))\n",
    "\n",
    "print(\"Num of rows in combined dataframe: \" + str(df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "|userId|movieId|rating|genres_le|tags_le| timestamp|               title|prediction|\n",
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "|   597|    471|   2.0|      634|    520| 941558175|Hudsucker Proxy, ...| 4.1348867|\n",
      "|   603|    471|   4.0|      634|    520| 954482443|Hudsucker Proxy, ...|   3.54139|\n",
      "|   218|    471|   4.0|      634|    520|1111624874|Hudsucker Proxy, ...|  2.900381|\n",
      "|   474|    471|   3.0|      634|    991| 974668858|Hudsucker Proxy, ...| 3.4150596|\n",
      "|   387|    471|   3.0|      634|    520|1139047519|Hudsucker Proxy, ...| 3.4201646|\n",
      "|   171|    471|   3.0|      634|    520| 866905683|Hudsucker Proxy, ...|  4.209692|\n",
      "|   541|    471|   3.0|      634|    520| 835643551|Hudsucker Proxy, ...|  3.833968|\n",
      "|   104|    471|   4.5|      634|    520|1238111129|Hudsucker Proxy, ...| 3.3618152|\n",
      "|   609|    833|   3.0|      634|    520| 847221080|High School High ...| 1.8917193|\n",
      "|   159|   1088|   4.0|      856|    520|1508641161|Dirty Dancing (1987)| 2.7695136|\n",
      "|   474|   1088|   3.5|      856|    790|1100292226|Dirty Dancing (1987)| 2.8829615|\n",
      "|    64|   1088|   4.0|      856|    520|1161559902|Dirty Dancing (1987)| 3.5209382|\n",
      "|   381|   1088|   3.5|      856|    520|1168664508|Dirty Dancing (1987)| 3.8622024|\n",
      "|   391|   1088|   1.0|      856|    520|1030824424|Dirty Dancing (1987)| 3.1206582|\n",
      "|    10|   1088|   3.0|      856|    520|1455619275|Dirty Dancing (1987)| 3.0925086|\n",
      "|    68|   1088|   3.5|      856|    520|1158534614|Dirty Dancing (1987)| 3.2160602|\n",
      "|   325|   1238|   4.0|      634|    520|1039399025|   Local Hero (1983)| 4.3850274|\n",
      "|   312|   1342|   4.0|      922|    520|1043176290|     Candyman (1992)|  2.695213|\n",
      "|   599|   1580|   3.0|      220|    520|1498525900|Men in Black (a.k...|  2.898407|\n",
      "|   111|   1580|   3.0|      220|    520|1516140709|Men in Black (a.k...|  2.703762|\n",
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the ratings dataframe into training and test data\n",
    "(training_data, test_data) = df.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "# Set the ALS hyperparameters\n",
    "als_fsm = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", nonnegative =True, implicitPrefs = False)\n",
    "\n",
    "# Fit the model to the training_data\n",
    "fsm = als_fsm.fit(training_data)\n",
    "\n",
    "# Generate predictions on the test_data\n",
    "test_predictions = fsm.transform(test_data)\n",
    "test_predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build RMSE evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730344272005154\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the \"test_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ALS model\n",
    "# als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "#           coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "# param_grid = ParamGridBuilder() \\\n",
    "#             .addGrid(als.alpha, [0, .25, .5, .75, 1]) \\\n",
    "#             .addGrid(als.rank, [10, 25, 50, 75, 100]) \\\n",
    "#             .addGrid(als.regParam, [.05, .1, .15, .2]) \\\n",
    "#             .addGrid(als.maxIter, [5, 25, 50, 75, 100]) \\\n",
    "#             .build()\n",
    "\n",
    "\n",
    "# print length of evaluator\n",
    "# print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "# cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cross validator to the 'train' dataset\n",
    "# model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best model from the cv model above\n",
    "# best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code below to extract the ALS model parameters\n",
    "# print(\"**Best Model**\")\n",
    "\n",
    "# rank: 50\n",
    "# regParam=0.15\n",
    "# alpha=0\n",
    "\n",
    "# Print \"ParamMap\"\n",
    "# print(\"\\n\\n  ParamMap:\", best_model._java_obj.parent().extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "|userId|movieId|rating|genres_le|tags_le| timestamp|               title|prediction|\n",
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "|   597|    471|   2.0|      634|    520| 941558175|Hudsucker Proxy, ...|  4.160037|\n",
      "|   603|    471|   4.0|      634|    520| 954482443|Hudsucker Proxy, ...| 3.1859825|\n",
      "|   218|    471|   4.0|      634|    520|1111624874|Hudsucker Proxy, ...| 2.9703295|\n",
      "|   474|    471|   3.0|      634|    991| 974668858|Hudsucker Proxy, ...| 3.2990625|\n",
      "|   387|    471|   3.0|      634|    520|1139047519|Hudsucker Proxy, ...| 3.1886456|\n",
      "|   171|    471|   3.0|      634|    520| 866905683|Hudsucker Proxy, ...|  4.216942|\n",
      "|   541|    471|   3.0|      634|    520| 835643551|Hudsucker Proxy, ...| 3.6519241|\n",
      "|   104|    471|   4.5|      634|    520|1238111129|Hudsucker Proxy, ...|  3.426191|\n",
      "|   609|    833|   3.0|      634|    520| 847221080|High School High ...| 1.5611655|\n",
      "|   159|   1088|   4.0|      856|    520|1508641161|Dirty Dancing (1987)| 2.9078665|\n",
      "+------+-------+------+---------+-------+----------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New model with best params\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          alpha=0, rank=50, regParam=0.15, maxIter=10,\n",
    "          coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = False)\n",
    "# Fit model to train\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Use mode to predict on test\n",
    "test_predictions = model.transform(test_data)\n",
    "test_predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8673723199273932\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the \"test_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|prediction|               title|              genres|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "| 132333|     1|  5.693803|         Seve (2014)|   Documentary|Drama|\n",
      "|   5915|     1|  5.545244|Victory (a.k.a. E...|    Action|Drama|War|\n",
      "|   5490|     1|  5.693803|  The Big Bus (1976)|       Action|Comedy|\n",
      "|  33649|     1| 5.4943852|  Saving Face (2004)|Comedy|Drama|Romance|\n",
      "|   7842|     1| 5.6125774|         Dune (2000)|Drama|Fantasy|Sci-Fi|\n",
      "| 117531|     2|   4.67297|    Watermark (2014)|         Documentary|\n",
      "|   7071|     2|   4.67297|Woman Under the I...|               Drama|\n",
      "|  26073|     2|   4.67297|Human Condition I...|           Drama|War|\n",
      "| 179135|     2|   4.67297|Blue Planet II (2...|         Documentary|\n",
      "|  84273|     2|   4.67297|Zeitgeist: Moving...|         Documentary|\n",
      "|   6835|     3| 4.8442287|Alien Contaminati...|Action|Horror|Sci-Fi|\n",
      "|   5181|     3|  4.739126|    Hangar 18 (1980)|Action|Sci-Fi|Thr...|\n",
      "|  70946|     3|  4.556531|      Troll 2 (1990)|      Fantasy|Horror|\n",
      "|   7991|     3| 4.8442287|Death Race 2000 (...|       Action|Sci-Fi|\n",
      "|   4518|     3|  4.540136|The Lair of the W...|       Comedy|Horror|\n",
      "|   1283|     4| 4.5123744|    High Noon (1952)|       Drama|Western|\n",
      "|   7700|     4| 4.6335797|Wages of Fear, Th...|Action|Adventure|...|\n",
      "|   1046|     4|  4.619817|Beautiful Thing (...|       Drama|Romance|\n",
      "|   2204|     4| 4.5605216|     Saboteur (1942)|    Mystery|Thriller|\n",
      "|   1733|     4|  4.766631|    Afterglow (1997)|       Drama|Romance|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.registerTempTable(\"ALS_recs_temp\")\n",
    "clean_recs = spark.sql(\"SELECT userId, movieIds_and_ratings.movieId AS movieId, movieIds_and_ratings.rating AS prediction FROM ALS_recs_temp LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")\n",
    "clean_recs = clean_recs.join(movies, on=['movieId'], how='left').sort('userId')\n",
    "clean_recs.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
