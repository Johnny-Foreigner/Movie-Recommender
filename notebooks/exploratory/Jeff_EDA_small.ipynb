{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-07 15:41:56--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘../../data/ml-latest-small.zip’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K  1.15MB/s    in 0.8s    \n",
      "\n",
      "2020-11-07 15:41:57 (1.15 MB/s) - ‘../../data/ml-latest-small.zip’ saved [978202/978202]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P ../../data http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('../../data/ml-latest-small.zip', 'r') as zip_ref: zip_ref.extractall('../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('../../data/ml-latest-small/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId\n",
       "0        1  114709    862.0\n",
       "1        2  113497   8844.0\n",
       "2        3  113228  15602.0\n",
       "3        4  114885  31357.0\n",
       "4        5  113041  11862.0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   movieId  9742 non-null   int64  \n",
      " 1   imdbId   9742 non-null   int64  \n",
      " 2   tmdbId   9734 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 228.5 KB\n"
     ]
    }
   ],
   "source": [
    "links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../../data/ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9742 non-null   int64 \n",
      " 1   title    9742 non-null   object\n",
      " 2   genres   9742 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../../data/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('../../data/ml-latest-small/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0       2    60756            funny  1445714994\n",
       "1       2    60756  Highly quotable  1445714996\n",
       "2       2    60756     will ferrell  1445714992\n",
       "3       2    89774     Boxing story  1445715207\n",
       "4       2    89774              MMA  1445715200"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3683 entries, 0 to 3682\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   userId     3683 non-null   int64 \n",
      " 1   movieId    3683 non-null   int64 \n",
      " 2   tag        3683 non-null   object\n",
      " 3   timestamp  3683 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 115.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import necessary libraries\n",
    "# from pyspark.sql import SparkSession\n",
    "# # instantiate SparkSession object\n",
    "# # spark = SparkSession.builder.master('local').getOrCreate()\n",
    "# spark = SparkSession\\\n",
    "#         .builder\\\n",
    "#         .appName('ALSExample').config('spark.driver.host', 'localhost')\\\n",
    "#         .getOrCreate()\n",
    "# # read in the dataset into pyspark DataFrame\n",
    "# links = spark.read.csv('../../data/ml-latest-small/links.csv', header='true', inferSchema='true')\n",
    "# movies = spark.read.csv('../../data/ml-latest-small/movies.csv', header='true', inferSchema='true')\n",
    "# ratings = spark.read.csv('../../data/ml-latest-small/ratings.csv', header='true', inferSchema='true')\n",
    "# tags = spark.read.csv('../../data/ml-latest-small/tags.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId                               title  \\\n",
       "0        1  114709    862.0                    Toy Story (1995)   \n",
       "1        2  113497   8844.0                      Jumanji (1995)   \n",
       "2        3  113228  15602.0             Grumpier Old Men (1995)   \n",
       "3        4  114885  31357.0            Waiting to Exhale (1995)   \n",
       "4        5  113041  11862.0  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged links and movies\n",
    "movie_ratings = links.merge(movies, on=[\"movieId\"])\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1106635946</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  imdbId  tmdbId             title  \\\n",
       "0       1        1     4.0   964982703  114709   862.0  Toy Story (1995)   \n",
       "1       5        1     4.0   847434962  114709   862.0  Toy Story (1995)   \n",
       "2       7        1     4.5  1106635946  114709   862.0  Toy Story (1995)   \n",
       "3      15        1     2.5  1510577970  114709   862.0  Toy Story (1995)   \n",
       "4      17        1     4.5  1305696483  114709   862.0  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = ratings.merge(movie_ratings, on=[\"movieId\"])\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId_x</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp_x</th>\n",
       "      <th>userId_y</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp_y</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714980</td>\n",
       "      <td>838283</td>\n",
       "      <td>12133.0</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1455749449</td>\n",
       "      <td>838283</td>\n",
       "      <td>12133.0</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "      <td>62</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1528934376</td>\n",
       "      <td>838283</td>\n",
       "      <td>12133.0</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1269123243</td>\n",
       "      <td>838283</td>\n",
       "      <td>12133.0</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "      <td>73</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1464196221</td>\n",
       "      <td>838283</td>\n",
       "      <td>12133.0</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId_x  movieId    tag  timestamp_x  userId_y  rating  timestamp_y  \\\n",
       "0         2    60756  funny   1445714994         2     5.0   1445714980   \n",
       "1         2    60756  funny   1445714994        18     3.0   1455749449   \n",
       "2         2    60756  funny   1445714994        62     3.5   1528934376   \n",
       "3         2    60756  funny   1445714994        68     2.5   1269123243   \n",
       "4         2    60756  funny   1445714994        73     4.5   1464196221   \n",
       "\n",
       "   imdbId   tmdbId                 title  genres  \n",
       "0  838283  12133.0  Step Brothers (2008)  Comedy  \n",
       "1  838283  12133.0  Step Brothers (2008)  Comedy  \n",
       "2  838283  12133.0  Step Brothers (2008)  Comedy  \n",
       "3  838283  12133.0  Step Brothers (2008)  Comedy  \n",
       "4  838283  12133.0  Step Brothers (2008)  Comedy  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = tags.merge(movie_ratings, on=[\"movieId\"])\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 233213 entries, 0 to 233212\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   userId_x     233213 non-null  int64  \n",
      " 1   movieId      233213 non-null  int64  \n",
      " 2   tag          233213 non-null  object \n",
      " 3   timestamp_x  233213 non-null  int64  \n",
      " 4   userId_y     233213 non-null  int64  \n",
      " 5   rating       233213 non-null  float64\n",
      " 6   timestamp_y  233213 non-null  int64  \n",
      " 7   imdbId       233213 non-null  int64  \n",
      " 8   tmdbId       233213 non-null  float64\n",
      " 9   title        233213 non-null  object \n",
      " 10  genres       233213 non-null  object \n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Matrix Factorization with ALS to Build a Collaborative Filtering Movie Recommendation Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PySpark, NumPy, IPython\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a spark session\n",
    "spark = SparkSession.builder.appName('FSM').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df = spark.read.csv('../../data/ml-latest-small/ratings.csv', inferSchema=True, header=True)\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "+------+-------+------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df = spark.read.csv('../../data/ml-latest-small/movies.csv', inferSchema=True, header=True)\n",
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- imdbId: integer (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links_df = spark.read.csv('../../data/ml-latest-small/links.csv', inferSchema=True, header=True)\n",
    "links_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_df = spark.read.csv('../../data/ml-latest-small/tags.csv', inferSchema=True, header=True)\n",
    "tags_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "# ALS requires numeric data, our data is already numeric\n",
    "training_df, validation_df = ratings_df.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS requires the following parameters\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "rank = 4\n",
    "errors = []\n",
    "err = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean_square error = 0.8868249823200508\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=4, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "model = als.fit(training_df)\n",
    "predictions = model.transform(validation_df)\n",
    "new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print(\"Root-mean_square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean_square error = 0.8840305708681246\n",
      "Root-mean_square error = 0.8877305104104398\n",
      "Root-mean_square error = 0.8837197252045196\n",
      "Root-mean_square error = 0.8916516039700236\n",
      "Root-mean_square error = 0.894832573435923\n",
      "Root-mean_square error = 0.8926116127840896\n"
     ]
    }
   ],
   "source": [
    "# this code checks rmse for ranks 4 - 10\n",
    "for rank in range(4,10):\n",
    "    als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "    model = als.fit(training_df)\n",
    "    predictions = model.transform(validation_df)\n",
    "    new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(new_predictions)\n",
    "    print(\"Root-mean_square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean_square error = 0.8772808109883926\n"
     ]
    }
   ],
   "source": [
    "# change rank to 8, based on above code, this is the highest rmse score\n",
    "als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=8, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "model = als.fit(training_df)\n",
    "predictions = model.transform(validation_df)\n",
    "new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print(\"Root-mean_square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is supposed to  check cross val scores for ranks 4-10 but takes a long time to run and I couldn't\n",
    "# figure out how to print out the scores\n",
    "\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# ls = ALS(maxIter=iterations, regParam=regularization_parameter, rank=rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(als.regParam, [0.1, 0.01, 0.18]) \\\n",
    "#     .addGrid(als.rank, range(4, 10)) \\\n",
    "#     .build()\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "# crossval = CrossValidator(estimator=als,\n",
    "#                           estimatorParamMaps=paramGrid,\n",
    "#                           evaluator=evaluator,\n",
    "#                           numFolds=5)\n",
    "# cvModel = crossval.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   191|    148|   5.0| 829760897|       NaN|\n",
      "|   520|    471|   5.0|1326609921| 3.7186322|\n",
      "|   448|    471|   4.0|1178980875| 3.6630256|\n",
      "|   608|    471|   1.5|1117161794| 2.5045674|\n",
      "|   191|    496|   5.0| 829760898|       NaN|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+----------+\n",
      "|userId|               title|              genres|prediction|\n",
      "+------+--------------------+--------------------+----------+\n",
      "|   191|Awfully Big Adven...|               Drama|       NaN|\n",
      "|   520|Hudsucker Proxy, ...|              Comedy| 3.7186322|\n",
      "|   448|Hudsucker Proxy, ...|              Comedy| 3.6630256|\n",
      "|   608|Hudsucker Proxy, ...|              Comedy| 2.5045674|\n",
      "|   191|What Happened Was...|Comedy|Drama|Roma...|       NaN|\n",
      "+------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.join(movies_df, \"movieId\").select(\"userId\",\"title\",\"genres\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------+----------+\n",
      "|userId|               title|              genres|tmdbId|prediction|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "|   599|American Splendor...|        Comedy|Drama|  2771| 3.4156573|\n",
      "|   599|     Sky High (2003)|Action|Horror|Thr...|  5846|       NaN|\n",
      "|   599|Bonnie and Clyde ...|         Crime|Drama|   475| 3.2393277|\n",
      "|   599|      Titanic (1997)|       Drama|Romance|   597|  2.492839|\n",
      "|   599|Prestige, The (2006)|Drama|Mystery|Sci...|  1124| 3.2368648|\n",
      "+------+--------------------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for_one_user = predictions.filter(col(\"userId\")==599).join(movies_df, \"movieId\").join(links_df, \"movieId\").select(\"userId\",\"title\",\"genres\",\"tmdbId\",\"prediction\")\n",
    "for_one_user.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Splendor (2003)\n"
     ]
    }
   ],
   "source": [
    "# create code to open web browsers for recommended movies\n",
    "import webbrowser\n",
    "link = \"https://www.themoviedb.org/movie/\"\n",
    "for movie in for_one_user.take(1):\n",
    "    movieURL = link+str(movie.tmdbId)\n",
    "    print(movie.title)\n",
    "    webbrowser.open(movieURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate top 5 movie recommendations for each user\n",
    "userRecomments = model.recommendForAllUsers(5)\n",
    "# generate top 5 user recommendations for each movie\n",
    "movieRecomments = model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecomments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------+\n",
      "|userId|movieId                            |\n",
      "+------+-----------------------------------+\n",
      "|471   |[6818, 89904, 6460, 7096, 213]     |\n",
      "|463   |[7842, 59018, 7841, 60943, 6818]   |\n",
      "|496   |[6818, 25771, 148881, 96004, 40491]|\n",
      "|148   |[89904, 86320, 98491, 2843, 49347] |\n",
      "|540   |[7842, 96004, 60943, 59018, 7841]  |\n",
      "+------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecomments.select(\"userId\",\"recommendations.movieId\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------+\n",
      "|movieId|UserId                  |\n",
      "+-------+------------------------+\n",
      "|1580   |[53, 12, 543, 452, 43]  |\n",
      "|4900   |[53, 371, 452, 122, 523]|\n",
      "|5300   |[375, 53, 296, 535, 295]|\n",
      "|6620   |[236, 418, 375, 535, 53]|\n",
      "|7340   |[43, 594, 578, 53, 162] |\n",
      "+-------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRecomments.select(\"movieId\",\"recommendations.UserId\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|   148|\n",
      "|   463|\n",
      "|   471|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = ratings_df.select(\"userId\").distinct().limit(3);\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[6818, 4.9396324...|\n",
      "|   463|[[7842, 5.1208186...|\n",
      "|   148|[[89904, 5.070490...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs = model.recommendForUserSubset(users, 5)\n",
    "userSubsetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------+\n",
      "|userId|movieId                           |\n",
      "+------+----------------------------------+\n",
      "|471   |[6818, 89904, 6460, 7096, 213]    |\n",
      "|463   |[7842, 59018, 7841, 60943, 6818]  |\n",
      "|148   |[89904, 86320, 98491, 2843, 49347]|\n",
      "+------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.select(\"userId\",\"recommendations.movieId\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|movieId|\n",
      "+-------+\n",
      "|   1580|\n",
      "|   2366|\n",
      "|   3175|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = ratings_df.select(\"movieId\").distinct().limit(3)\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|movieId|UserId                |\n",
      "+-------+----------------------+\n",
      "|1580   |[53, 12, 543, 452, 43]|\n",
      "|3175   |[53, 543, 236, 43, 12]|\n",
      "|2366   |[53, 224, 69, 451, 43]|\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieSubsetRecs = model.recommendForItemSubset(movies, 5)\n",
    "movieSubsetRecs.select(\"movieId\", \"recommendations.UserId\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for some movie for a specific user\n",
    "movie_ids = [1580,3175,2366,1590]\n",
    "user_ids = [543,543,543,543]\n",
    "new_user_preds = sqlContext.createDataFrame(zip(movie_ids, user_ids), schema=['movieId','userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|   1580|   543| 4.6211176|\n",
      "|   2366|   543| 3.2962856|\n",
      "|   3175|   543|  4.654319|\n",
      "|   1590|   543|  2.878671|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_predictions = model.transform(new_user_preds)\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New combined list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+--------------------+--------------------+----+---------+\n",
      "|userId|movieId|rating|timestamp|               title|              genres| tag|timestamp|\n",
      "+------+-------+------+---------+--------------------+--------------------+----+---------+\n",
      "|     1|      1|   4.0|964982703|    Toy Story (1995)|Adventure|Animati...|null|     null|\n",
      "|     1|      3|   4.0|964981247|Grumpier Old Men ...|      Comedy|Romance|null|     null|\n",
      "|     1|      6|   4.0|964982224|         Heat (1995)|Action|Crime|Thri...|null|     null|\n",
      "|     1|     47|   5.0|964983815|Seven (a.k.a. Se7...|    Mystery|Thriller|null|     null|\n",
      "|     1|     50|   5.0|964982931|Usual Suspects, T...|Crime|Mystery|Thr...|null|     null|\n",
      "|     1|     70|   3.0|964982400|From Dusk Till Da...|Action|Comedy|Hor...|null|     null|\n",
      "|     1|    101|   5.0|964980868|Bottle Rocket (1996)|Adventure|Comedy|...|null|     null|\n",
      "|     1|    110|   4.0|964982176|   Braveheart (1995)|    Action|Drama|War|null|     null|\n",
      "|     1|    151|   5.0|964984041|      Rob Roy (1995)|Action|Drama|Roma...|null|     null|\n",
      "|     1|    157|   5.0|964984100|Canadian Bacon (1...|          Comedy|War|null|     null|\n",
      "|     1|    163|   5.0|964983650|    Desperado (1995)|Action|Romance|We...|null|     null|\n",
      "|     1|    216|   5.0|964981208|Billy Madison (1995)|              Comedy|null|     null|\n",
      "|     1|    223|   3.0|964980985|       Clerks (1994)|              Comedy|null|     null|\n",
      "|     1|    231|   5.0|964981179|Dumb & Dumber (Du...|    Adventure|Comedy|null|     null|\n",
      "|     1|    235|   4.0|964980908|      Ed Wood (1994)|        Comedy|Drama|null|     null|\n",
      "|     1|    260|   5.0|964981680|Star Wars: Episod...|Action|Adventure|...|null|     null|\n",
      "|     1|    296|   3.0|964982967| Pulp Fiction (1994)|Comedy|Crime|Dram...|null|     null|\n",
      "|     1|    316|   3.0|964982310|     Stargate (1994)|Action|Adventure|...|null|     null|\n",
      "|     1|    333|   5.0|964981179|    Tommy Boy (1995)|              Comedy|null|     null|\n",
      "|     1|    349|   4.0|964982563|Clear and Present...|Action|Crime|Dram...|null|     null|\n",
      "+------+-------+------+---------+--------------------+--------------------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = ratings_df.join(movies_df, [\"movieID\"], \"left\")\n",
    "df = df.join(tags_df, [\"userID\", \"movieID\"], \"left\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of users: 610\n",
      "Num of movies: 9724\n",
      "Num of tags: 1544\n",
      "Num of rows in ratings: userId       100836\n",
      "movieId      100836\n",
      "rating       100836\n",
      "timestamp    100836\n",
      "dtype: int64\n",
      "Num of rows in tags: userId       3683\n",
      "movieId      3683\n",
      "tag          3683\n",
      "timestamp    3683\n",
      "dtype: int64\n",
      "Num of rows in combined dataframe: 102677\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of users: \" + str(df.groupBy(\"userID\").count().count()))\n",
    "print(\"Num of movies: \" + str(df.groupBy(\"movieID\").count().count()))\n",
    "print(\"Num of tags: \" + str(df.groupBy(\"tag\").count().count()))\n",
    "print(\"Num of rows in ratings: \" + str(ratings.count()))\n",
    "print(\"Num of rows in tags: \" + str(tags.count()))\n",
    "print(\"Num of rows in combined dataframe: \" + str(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "# ALS requires numeric data, our data contains strings\n",
    "training_df, validation_df = df.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean_square error = 0.6548761138109392\n"
     ]
    }
   ],
   "source": [
    "# Build another model with combined dataframe\n",
    "als = ALS(alpha=0, maxIter=iterations, regParam=regularization_parameter, rank=50, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "new_model = als.fit(training_df)\n",
    "predictions = model.transform(validation_df)\n",
    "new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print(\"Root-mean_square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+--------------------+------+----+---------+----------+\n",
      "|userId|movieId|rating|timestamp|               title|genres| tag|timestamp|prediction|\n",
      "+------+-------+------+---------+--------------------+------+----+---------+----------+\n",
      "|   597|    471|   2.0|941558175|Hudsucker Proxy, ...|Comedy|null|     null| 3.8203557|\n",
      "|   436|    471|   3.0|833530187|Hudsucker Proxy, ...|Comedy|null|     null|  3.631647|\n",
      "|   409|    471|   3.0|967912821|Hudsucker Proxy, ...|Comedy|null|     null| 4.0115466|\n",
      "|   372|    471|   3.0|874415126|Hudsucker Proxy, ...|Comedy|null|     null| 3.2891638|\n",
      "|    32|    471|   3.0|856737165|Hudsucker Proxy, ...|Comedy|null|     null| 3.9300745|\n",
      "+------+-------+------+---------+--------------------+------+----+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|prediction|               title|              genres|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "|   1262|     1| 5.3404207|Great Escape, The...|Action|Adventure|...|\n",
      "|   3494|     1| 5.2827806|    True Grit (1969)|Adventure|Drama|W...|\n",
      "|   5915|     1|  5.210826|Victory (a.k.a. E...|    Action|Drama|War|\n",
      "|   1204|     1|  5.192298|Lawrence of Arabi...| Adventure|Drama|War|\n",
      "|   3653|     1| 5.2183743|Endless Summer, T...|         Documentary|\n",
      "| 106782|     2| 4.6645274|Wolf of Wall Stre...|  Comedy|Crime|Drama|\n",
      "|  60756|     2| 4.6924524|Step Brothers (2008)|              Comedy|\n",
      "|  89774|     2| 4.6892004|      Warrior (2011)|               Drama|\n",
      "|  80906|     2|  4.562723|   Inside Job (2010)|         Documentary|\n",
      "| 131724|     2| 4.9094415|The Jinx: The Lif...|         Documentary|\n",
      "|   5919|     3|  4.852443|      Android (1982)|              Sci-Fi|\n",
      "|   7991|     3|  4.772474|Death Race 2000 (...|       Action|Sci-Fi|\n",
      "|   6835|     3| 4.9102697|Alien Contaminati...|Action|Horror|Sci-Fi|\n",
      "|  70946|     3| 4.9003615|      Troll 2 (1990)|      Fantasy|Horror|\n",
      "|   5181|     3|  4.841819|    Hangar 18 (1980)|Action|Sci-Fi|Thr...|\n",
      "|   1046|     4| 4.8690643|Beautiful Thing (...|       Drama|Romance|\n",
      "|   2204|     4|  4.926112|     Saboteur (1942)|    Mystery|Thriller|\n",
      "|   1733|     4|   4.85517|    Afterglow (1997)|       Drama|Romance|\n",
      "|   3851|     4|  4.926112|I'm the One That ...|              Comedy|\n",
      "|   4765|     4|  4.926112|       L.I.E. (2001)|               Drama|\n",
      "+-------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Reference 'userId' is ambiguous, could be: userId, userId.;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-d37545a96618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# join predictions with the movies df to show the movie name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"userId\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"genres\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Reference 'userId' is ambiguous, could be: userId, userId.;"
     ]
    }
   ],
   "source": [
    "# Make 5 movie recommendations per user using their highest predicted ratings\n",
    "recommendations = new_model.recommendForAllUsers(5)\n",
    "# Print Some Prediction\n",
    "recommendations.registerTempTable(\"ALS_recs_temp\")\n",
    "clean_recs = spark.sql(\"SELECT userId, movieIds_and_ratings.movieId AS movieId, movieIds_and_ratings.rating AS prediction FROM ALS_recs_temp LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")\n",
    "clean_recs = clean_recs.join(movies_df, on=['movieId'], how='left').sort('userId')\n",
    "clean_recs.show()\n",
    "\n",
    "# join predictions with the movies df to show the movie name\n",
    "predictions.join(df, \"movieId\").select(\"userId\",\"title\",\"genres\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_one_user = predictions.filter(col(\"userId\")==599).join(movies_df, \"movieId\").join(links_df, \"movieId\").select(\"userId\",\"title\",\"genres\",\"tmdbId\",\"prediction\")\n",
    "# for_one_user.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to open web browsers for recommended movies\n",
    "# import webbrowser\n",
    "# link = \"https://www.themoviedb.org/movie/\"\n",
    "# for movie in for_one_user.take(1):\n",
    "#     movieURL = link+str(movie.tmdbId)\n",
    "#     print(movie.title)\n",
    "#     webbrowser.open(movieURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate top 5 movie recommendations for each user\n",
    "userRecomments = new_model.recommendForAllUsers(5)\n",
    "# generate top 5 user recommendations for each movie\n",
    "movieRecomments = new_model.recommendForAllItems(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------+\n",
      "|userId|movieId                             |\n",
      "+------+------------------------------------+\n",
      "|471   |[2324, 89904, 1203, 98491, 79702]   |\n",
      "|463   |[78836, 5466, 5952, 30745, 159817]  |\n",
      "|496   |[858, 5618, 7099, 7767, 89759]      |\n",
      "|148   |[98491, 33649, 160718, 89904, 78836]|\n",
      "|540   |[78836, 159817, 296, 92535, 177593] |\n",
      "+------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecomments.select(\"userId\",\"recommendations.movieId\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "|_c0|userID|rating|movieID|               title|              genres|   tag|timestamp|\n",
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "|  0|     1|   4.0|   1208|Apocalypse Now (1...|    Action|Drama|War|Uknown|     null|\n",
      "|  1|     1|   4.0|   1348|Nosferatu (Nosfer...|              Horror|Uknown|     null|\n",
      "|  2|     4|   5.0|    457|Fugitive, The (1993)|            Thriller|Uknown|     null|\n",
      "|  3|     4|   2.0|    599|Wild Bunch, The (...|   Adventure|Western|Uknown|     null|\n",
      "|  4|     6|   4.0|    274|Man of the House ...|              Comedy|Uknown|     null|\n",
      "|  5|     6|   1.0|    327|    Tank Girl (1995)|Action|Comedy|Sci-Fi|Uknown|     null|\n",
      "|  6|     6|   3.0|    520|Robin Hood: Men i...|              Comedy|Uknown|     null|\n",
      "|  7|     7|   4.0|   1101|      Top Gun (1986)|      Action|Romance|Uknown|     null|\n",
      "|  8|     8|   3.0|    235|      Ed Wood (1994)|        Comedy|Drama|Uknown|     null|\n",
      "|  9|     9|   5.0|   5481|Austin Powers in ...|              Comedy|Uknown|     null|\n",
      "| 10|    10|   4.0| 109853|     Barefoot (2014)|Comedy|Drama|Romance|Uknown|     null|\n",
      "| 11|    18|   4.0|   1721|      Titanic (1997)|       Drama|Romance|Uknown|     null|\n",
      "| 12|    18|   4.0|   1892|Perfect Murder, A...|            Thriller|Uknown|     null|\n",
      "| 13|    18|   4.0|   3896|Way of the Gun, T...|      Crime|Thriller|Uknown|     null|\n",
      "| 14|    18|   4.0|   4963|Ocean's Eleven (2...|      Crime|Thriller|Uknown|     null|\n",
      "| 15|    19|   3.0|   1259|  Stand by Me (1986)|     Adventure|Drama|Uknown|     null|\n",
      "| 16|    19|   2.0|   2548|Rage: Carrie 2, T...|              Horror|Uknown|     null|\n",
      "| 17|    19|   4.0|   2762|Sixth Sense, The ...|Drama|Horror|Mystery|Uknown|     null|\n",
      "| 18|    19|   2.0|   3704|Mad Max Beyond Th...|Action|Adventure|...|Uknown|     null|\n",
      "| 19|    21|   3.0| 126548|     The DUFF (2015)|              Comedy|Uknown|     null|\n",
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('../../data/cleaned_movies_df.csv', inferSchema=True, header=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data = data.where(col(\"tag\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.na.drop(subset=[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "|_c0|userID|rating|movieID|               title|              genres|   tag|timestamp|\n",
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "|  0|     1|   4.0|   1208|Apocalypse Now (1...|    Action|Drama|War|Uknown|     null|\n",
      "|  1|     1|   4.0|   1348|Nosferatu (Nosfer...|              Horror|Uknown|     null|\n",
      "|  2|     4|   5.0|    457|Fugitive, The (1993)|            Thriller|Uknown|     null|\n",
      "|  3|     4|   2.0|    599|Wild Bunch, The (...|   Adventure|Western|Uknown|     null|\n",
      "|  4|     6|   4.0|    274|Man of the House ...|              Comedy|Uknown|     null|\n",
      "|  5|     6|   1.0|    327|    Tank Girl (1995)|Action|Comedy|Sci-Fi|Uknown|     null|\n",
      "|  6|     6|   3.0|    520|Robin Hood: Men i...|              Comedy|Uknown|     null|\n",
      "|  7|     7|   4.0|   1101|      Top Gun (1986)|      Action|Romance|Uknown|     null|\n",
      "|  8|     8|   3.0|    235|      Ed Wood (1994)|        Comedy|Drama|Uknown|     null|\n",
      "|  9|     9|   5.0|   5481|Austin Powers in ...|              Comedy|Uknown|     null|\n",
      "| 10|    10|   4.0| 109853|     Barefoot (2014)|Comedy|Drama|Romance|Uknown|     null|\n",
      "| 11|    18|   4.0|   1721|      Titanic (1997)|       Drama|Romance|Uknown|     null|\n",
      "| 12|    18|   4.0|   1892|Perfect Murder, A...|            Thriller|Uknown|     null|\n",
      "| 13|    18|   4.0|   3896|Way of the Gun, T...|      Crime|Thriller|Uknown|     null|\n",
      "| 14|    18|   4.0|   4963|Ocean's Eleven (2...|      Crime|Thriller|Uknown|     null|\n",
      "| 15|    19|   3.0|   1259|  Stand by Me (1986)|     Adventure|Drama|Uknown|     null|\n",
      "| 16|    19|   2.0|   2548|Rage: Carrie 2, T...|              Horror|Uknown|     null|\n",
      "| 17|    19|   4.0|   2762|Sixth Sense, The ...|Drama|Horror|Mystery|Uknown|     null|\n",
      "| 18|    19|   2.0|   3704|Mad Max Beyond Th...|Action|Adventure|...|Uknown|     null|\n",
      "| 19|    21|   3.0| 126548|     The DUFF (2015)|              Comedy|Uknown|     null|\n",
      "+---+------+------+-------+--------------------+--------------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'anti-intellectual',\n",
       " 'bad writing',\n",
       " 'dystopia',\n",
       " 'new society',\n",
       " 'plot holes',\n",
       " 'predictable',\n",
       " 'scifi',\n",
       " 'unintelligent',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Edith Wharton',\n",
       " 'Christmas',\n",
       " 'Halloween',\n",
       " 'vampires',\n",
       " 'reunion',\n",
       " 'Uknown',\n",
       " 'bluegrass',\n",
       " 'Graham Greene',\n",
       " 'child abuse',\n",
       " 'In Netflix queue',\n",
       " 'boxing',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'threesome',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'claustrophobic',\n",
       " 'horror',\n",
       " 'scary',\n",
       " 'stephen king',\n",
       " 'suspenseful',\n",
       " 'tense',\n",
       " 'thriller',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'time travel',\n",
       " 'England',\n",
       " 'Uknown',\n",
       " 'In Netflix queue',\n",
       " 'Uknown',\n",
       " 'In Netflix queue',\n",
       " 'Uknown',\n",
       " 'baseball',\n",
       " 'Lou Gehrig',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " '2D animation',\n",
       " 'cult film',\n",
       " 'stylish',\n",
       " 'surreal',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " 'Uknown',\n",
       " ...]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "my_list = data.select(f.collect_list('tag')).first()[0]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "# ALS requires numeric data, our data contains strings\n",
    "training_df, validation_df = data.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALS requires the following parameters\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "rank = 4\n",
    "errors = []\n",
    "err = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2999.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3515.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3515.0 (TID 16584, jeffreys-air, executor driver): java.lang.NullPointerException: Value at index 2 is null\n\tat org.apache.spark.sql.Row.getAnyValAs(Row.scala:523)\n\tat org.apache.spark.sql.Row.getFloat(Row.scala:262)\n\tat org.apache.spark.sql.Row.getFloat$(Row.scala:262)\n\tat org.apache.spark.sql.catalyst.expressions.GenericRow.getFloat(rows.scala:166)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$2(ALS.scala:700)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1227)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:960)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:709)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:691)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:593)\n\tat jdk.internal.reflect.GeneratedMethodAccessor171.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\nCaused by: java.lang.NullPointerException: Value at index 2 is null\n\tat org.apache.spark.sql.Row.getAnyValAs(Row.scala:523)\n\tat org.apache.spark.sql.Row.getFloat(Row.scala:262)\n\tat org.apache.spark.sql.Row.getFloat$(Row.scala:262)\n\tat org.apache.spark.sql.catalyst.expressions.GenericRow.getFloat(rows.scala:166)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$2(ALS.scala:700)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-ce26ecb19054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Build the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularization_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"userID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"movieID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratingCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnew_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2999.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3515.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3515.0 (TID 16584, jeffreys-air, executor driver): java.lang.NullPointerException: Value at index 2 is null\n\tat org.apache.spark.sql.Row.getAnyValAs(Row.scala:523)\n\tat org.apache.spark.sql.Row.getFloat(Row.scala:262)\n\tat org.apache.spark.sql.Row.getFloat$(Row.scala:262)\n\tat org.apache.spark.sql.catalyst.expressions.GenericRow.getFloat(rows.scala:166)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$2(ALS.scala:700)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1227)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:960)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:709)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:691)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:593)\n\tat jdk.internal.reflect.GeneratedMethodAccessor171.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\nCaused by: java.lang.NullPointerException: Value at index 2 is null\n\tat org.apache.spark.sql.Row.getAnyValAs(Row.scala:523)\n\tat org.apache.spark.sql.Row.getFloat(Row.scala:262)\n\tat org.apache.spark.sql.Row.getFloat$(Row.scala:262)\n\tat org.apache.spark.sql.catalyst.expressions.GenericRow.getFloat(rows.scala:166)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$2(ALS.scala:700)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Build another model with combined dataframe\n",
    "# Build the model\n",
    "als = ALS(maxIter=iterations, regParam=regularization_parameter, rank=4, userCol=\"userID\", itemCol=\"movieID\", ratingCol=\"rating\")\n",
    "model = als.fit(training_df)\n",
    "predictions = model.transform(validation_df)\n",
    "new_predictions = predictions.filter(col('prediction') != np.nan)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print(\"Root-mean_square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyaccomando/Documents/Flatiron/Phase_4_Project/Movie-Recommender/notebooks/exploratory\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
